{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoph and Lee (2016): 4.00 PFLOPS-day | 5265 Kwatt/hour | 4012 GCPWCC | 9597 EPAWCC | 5984 US AVE CO2\n",
      "Zoph et al (2017): 0.77 PFLOPS-day | 499 Kwatt/hour | 380 GCPWCC | 911 EPAWCC | 568 US AVE CO2\n",
      "Zhong et al. (2018): 0.34 PFLOPS-day | 179 Kwatt/hour | 136 GCPWCC | 326 EPAWCC | 203 US AVE CO2\n",
      "Elsken et al. (2018): 0.20 PFLOPS-day | 116 Kwatt/hour | 88 GCPWCC | 212 EPAWCC | 132 US AVE CO2\n",
      "OpenGo et al. (2018): 85.93 PFLOPS-day | 55440 Kwatt/hour | 42245 GCPWCC | 101047 EPAWCC | 63009 US AVE CO2\n",
      "Chen et al. (2018): 7.95 PFLOPS-day | 5128 Kwatt/hour | 3907 GCPWCC | 9346 EPAWCC | 5828 US AVE CO2\n",
      "OpenAI 1v1 Dota (2018): 13.23 PFLOPS-day | 10903 Kwatt/hour | 8308 GCPWCC | 19873 EPAWCC | 12392 US AVE CO2\n"
     ]
    }
   ],
   "source": [
    "# Calculations for compute based on https://blog.openai.com/ai-and-compute/\n",
    "# Method 2: #Total GPU Hours * #GPU-GFLOPS * .33 utilization\n",
    "\n",
    "UTILIZATION_CONSTANT = .33\n",
    "EPA_WORST_CASE_CO2_per_kilowatthr = 1822.65/1000.0\n",
    "GCP_WORST_CASE_CO2_per_kilowatthr = 762/1000.0\n",
    "US_AV_CO2_PER_kilowatthr = 1136.53/1000.0\n",
    "\n",
    "def print_stats(name, gpu_hours, pflops_per_gpu, gflop_watts, utilization_constant_use=True):\n",
    "\n",
    "    pflop_hours = pflops_per_gpu*gpu_hours # \n",
    "    util_const = 1.0 if not utilization_constant_use else UTILIZATION_CONSTANT\n",
    "    utilized_pflop_hours = pflop_hours *util_const\n",
    "    utilized_pflops_day = utilized_pflop_hours / 24.\n",
    "    utilized_gflops_day = utilized_pflops_day * (1000000 ) # gigaflops/1 petaflop\n",
    "    watt_day = utilized_gflops_day / gflop_watts\n",
    "    kwatt_day = watt_day / 1000.\n",
    "    kwatt_hour = kwatt_day * 24 # hours/day \n",
    "    GCP_emissions = kwatt_hour * GCP_WORST_CASE_CO2_per_kilowatthr\n",
    "    EPA_emissions = kwatt_hour * EPA_WORST_CASE_CO2_per_kilowatthr\n",
    "    AVE_EMISSONS = kwatt_hour * US_AV_CO2_PER_kilowatthr\n",
    "    print(\"{}: {:.2f} PFLOPS-day | {} Kwatt/hour | {} GCPWCC | {} EPAWCC | {} US AVE CO2\".format(name, utilized_pflops_day, int(kwatt_hour), int(GCP_emissions), int(EPA_emissions), int(AVE_EMISSONS)))\n",
    "\n",
    "# Zoph and Lee (2016)\n",
    "# 800 GPUs for 28 days resulting in 22,400 GPU-hours. Nvidia K40 GPUs\n",
    "gpu_hours = 22400  #800 * 28 * 24\n",
    "pflops_per_gpu = 0.00429 #4.29 Tflops for k40 https://www.nvidia.com/content/tesla/pdf/nvidia-tesla-kepler-family-datasheet.pdf\n",
    "gflop_watts = 18.25 # k40\n",
    "print_stats(\"Zoph and Lee (2016)\", gpu_hours, pflops_per_gpu, gflop_watts, utilization_constant_use=False)\n",
    "\n",
    "# Zoph et al. (2018)\n",
    "# 500 GPUs across 4 days resulting in 2,000 GPU-hours. NVidia P100s.\n",
    "gpu_hours = 2000 #500 * 4 * 24\n",
    "pflops_per_gpu = 0.0093 # P100 https://en.wikipedia.org/wiki/Nvidia_Tesla\n",
    "gflop_watts = 37.2 # p100\n",
    "print_stats(\"Zoph et al (2017)\", gpu_hours, pflops_per_gpu, gflop_watts, utilization_constant_use=False)\n",
    "\n",
    "# Zhong et al. (2018)\n",
    "# only spends\n",
    "# 3\n",
    "# days with\n",
    "# 32\n",
    "# GPUs,\n",
    "gpu_hours = 32 * 3 * 24\n",
    "pflops_per_gpu = 0.0106 # 1080ti\n",
    "gflop_watts = 45 # 1080ti\n",
    "print_stats(\"Zhong et al. (2018)\", gpu_hours, pflops_per_gpu, gflop_watts, utilization_constant_use=True)\n",
    "\n",
    "\n",
    "\n",
    "## Elsken et al.2018\n",
    "# https://arxiv.org/pdf/1804.09081.pdf#page=14&zoom=auto,-139,431\n",
    "# 56 GPU days \n",
    "# Titan X\n",
    "gpu_hours = 56 * 24\n",
    "pflops_per_gpu = 0.01079 # x\n",
    "gflop_watts = 41 # x\n",
    "print_stats(\"Elsken et al. (2018)\", gpu_hours, pflops_per_gpu, gflop_watts, utilization_constant_use=True)\n",
    "\n",
    "## Elf opengo et al.2018\n",
    "# 2000 GPUs for \n",
    "# assuming p100, not sure\n",
    "gpu_hours = 2000 * 14 * 24\n",
    "pflops_per_gpu = 0.0093 # P100 https://en.wikipedia.org/wiki/Nvidia_Tesla\n",
    "gflop_watts = 37.2 # p100\n",
    "print_stats(\"OpenGo et al. (2018)\", gpu_hours, pflops_per_gpu, gflop_watts, utilization_constant_use=True)\n",
    "\n",
    "\n",
    "## Chen et al.\n",
    "# 370 for 1 week\n",
    "# assume p100\n",
    "gpu_hours = 370 * 7 * 24\n",
    "pflops_per_gpu = 0.0093 # P100 https://en.wikipedia.org/wiki/Nvidia_Tesla\n",
    "gflop_watts = 37.2 # p100\n",
    "print_stats(\"Chen et al. (2018)\", gpu_hours, pflops_per_gpu, gflop_watts, utilization_constant_use=True)\n",
    "\n",
    "## OpenAI 1v1 Dota\n",
    "# 256 K80 GPUs for 18 days (from charts)\n",
    "gpu_hours = 256 * 18 * 24\n",
    "pflops_per_gpu = 0.0087 # P100 https://en.wikipedia.org/wiki/Nvidia_Tesla\n",
    "gflop_watts = 29.12 # p100\n",
    "print_stats(\"OpenAI 1v1 Dota (2018)\", gpu_hours, pflops_per_gpu, gflop_watts, utilization_constant_use=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
