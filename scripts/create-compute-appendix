#!/usr/bin/env python3

from __future__ import print_function

import argparse
import os
import sys
from datetime import datetime
import scipy
import numpy as np
from pprint import pprint
from experiment_impact_tracker.compute_tracker import (PUE,
                                                       load_data_into_frame,
                                                       load_initial_info)
from experiment_impact_tracker.stats import run_test, get_average_treatment_effect
from experiment_impact_tracker.emissions.common import get_realtime_carbon_source
from pylatex import (Axis, Document, Figure, LineBreak, Math, Package, Plot,
                     Section, Subsection, Subsubsection, Table, Tabular, TikZ)
from pylatex.utils import escape_latex
import json
from deepdiff import DeepDiff  # For Deep Difference of 2 objects
from itertools import combinations 
# def _easy_compare(dict_1, dict_2):
#     dump = json.dumps(dict_1, sort_keys=True)
#     dump2 = json.dumps(dict_2, sort_keys=True)
#     return dump == dump2 


# TODO: give experiment set a name and then iterate through each one
# TODO: Each individual one should make a new file and then a summary file and a differences file

def gather_additional_info(info, logdir):
    df = load_data_into_frame(logdir)
    num_gpus = len(info["gpu_info"])
    exp_len = df["timestamp"].iloc[-1] - \
        datetime.timestamp(info["experiment_start"])
    exp_len_hours = exp_len/3600.
    # integrate power
    # https://electronics.stackexchange.com/questions/237025/converting-watt-values-over-time-to-kwh
    # multiply by carbon intensity to get Kg Carbon eq

    time_differences = df["timestamp"].diff()
    time_differences[0] = df["timestamp"][0] - \
        datetime.timestamp(info["experiment_start"])
    # elementwise multiplication and sum
    time_differences_in_hours = time_differences/3600.
    power_draw_rapl_kw = df["rapl_estimated_attributable_power_draw"] / 1000.
    nvidia_power_draw_kw = df["nvidia_estimated_attributable_power_draw"] / 1000.
    # elementwise multiplication and sum
    kw_hr_nvidia = np.multiply(time_differences_in_hours, nvidia_power_draw_kw)
    kw_hr_rapl = np.multiply(time_differences_in_hours, power_draw_rapl_kw)

    total_power_per_timestep = PUE * (kw_hr_nvidia + kw_hr_rapl)
    total_power = total_power_per_timestep.sum()
    if "realtime_carbon_intensity" in df:
        estimated_carbon_impact_grams_per_timestep = np.multiply(total_power_per_timestep, df["realtime_carbon_intensity"])
        estimated_carbon_impact_grams = estimated_carbon_impact_grams_per_timestep.sum()
    else:
        estimated_carbon_impact_grams = total_power * \
            info["region_carbon_intensity_estimate"]["carbonIntensity"]
    
    estimated_carbon_impact_kg = estimated_carbon_impact_grams / 1000.0
    # GPU-hours percent utilization * length of time utilized (assumes absolute utliziation)
    gpu_hours = np.multiply(
        time_differences_in_hours, df["average_gpu_estimated_utilization_absolute"]).sum() * num_gpus

    cpu_hours = df['cpu_time_seconds'].iloc[-1]/3600.

    data = {
        "cpu_hours" : cpu_hours, 
        "gpu_hours" : gpu_hours,
        "estimated_carbon_impact_kg" : estimated_carbon_impact_kg,
        "total_power" : total_power,
        "kw_hr_gpu" : kw_hr_nvidia.sum(),
        "kw_hr_cpu" : kw_hr_rapl.sum(),
        "exp_len_hours" : exp_len_hours
     }

    if "realtime_carbon_intensity" in df:
        data["average_realtime_carbon_intensity"] = df["realtime_carbon_intensity"].mean()

    return data


def _format_setname(setname):
    return setname.lower().replace(" ", "_").replace("(", "").replace(")", "")

def _generate_files(doc, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    doc.generate_pdf(path)
    doc.generate_tex(path)


def _generate_experiment_table(logdir, info, extended_info, setname, set_experiment_number):
    doc=Document()
    with doc.create(Section('Experiment {} of set {}'.format(set_experiment_number, setname))):
        with doc.create(Subsection('Device and Version Information')):
            with doc.create(Subsubsection('CPU Information')):
                with doc.create(Tabular('|r|p{8cm}|')) as table:
                    table.add_hline()
                    for key, value in info['cpu_info'].items():
                        if isinstance(value, list):
                            value = ", ".join([str(x) for x in value])
                        table.add_row((key, value))
                        table.add_hline()
                # doc.append('Brand: ' + str(info["cpu_info"]["brand"]))
                # doc.append(LineBreak())
                # doc.append('Hz (Actual): ' +
                #    (str(info["cpu_info"]["hz_actual"])))
            with doc.create(Subsubsection('GPU Information')):
                num_gpus = len(info["gpu_info"])
                doc.append("Num GPUs: {}\n".format(num_gpus))
                for gpu in info["gpu_info"]:
                    with doc.create(Tabular('|r|p{8cm}|')) as table:
                        table.add_hline()
                        for key, value in gpu.items():
                            if isinstance(value, list):
                                value = ",".join(value)
                            table.add_row((key, value))
                            table.add_hline()
                # doc.append(LineBreak())
                # doc.append('GPU Info: ' +
                #            (",".join([x["name"] for x in info["gpu_info"]])))
                # TODO: more gpu info
            with doc.create(Subsubsection('Carbon Estimation Information')):
                with doc.create(Tabular('|r|p{8cm}|')) as table:
                    table.add_hline()
                    try:
                        table.add_row(['Experiment Impact Tracker Version',
                                    info["experiment_impact_tracker_version"]])
                    except KeyError:
                        table.add_row(['Experiment Impact Tracker Version',
                                    info["climate_impact_tracker_version"]])
                    table.add_hline()
                    table.add_row(('Compute Region', info["region"]["id"]))
                    table.add_hline()
                    if "average_realtime_carbon_intensity" in extended_info:
                        table.add_row(('average gCO2eq/kWh',
                            str(extended_info["average_realtime_carbon_intensity"])))
                        table.add_hline()
                        table.add_row(('Carbon Data Source', "Live Data From" + get_realtime_carbon_source(info["region"]["id"])))
                        table.add_hline()
                    else:
                        table.add_row(('region est. gCO2eq/kWh',
                                    str(info["region_carbon_intensity_estimate"]["carbonIntensity"])))
                        table.add_hline()
                        table.add_row(('Carbon Data Source', str(
                            info["region_carbon_intensity_estimate"]["_source"])))
                        table.add_hline()
                    table.add_row(('Assumed PUE', str(PUE)))
                    table.add_hline()


        with doc.create(Subsection('Experiment Info')):
            with doc.create(Tabular('|r|c|')) as table:
                table.add_hline()
                table.add_row(('Experiment Start Time', str(
                    datetime.timestamp(info["experiment_start"]))))
                table.add_hline()
                table.add_row(
                    ('Experiment Length (hours)', str(extended_info["exp_len_hours"])))
                table.add_hline()
                table.add_row(
                    ('Intel (CPU+DRAM, RAPL) Power Usage (kWh)', str(extended_info["kw_hr_cpu"])))
                table.add_hline()
                table.add_row('NVIDIA (GPU) Power Usage (kWh)',
                              str(extended_info["kw_hr_gpu"]))
                table.add_hline()
                table.add_row(
                    'Total (Including PUE Mult.) Power (kWh)', str(extended_info["total_power"]))
                table.add_hline()
                table.add_row(('Estimated Carbon Impact (kgCO2eq)',
                              str(extended_info["estimated_carbon_impact_kg"])))
                table.add_hline()
                table.add_row(('Final CPU-Hours (psutil estimate)',
                              str(extended_info["cpu_hours"])))
                table.add_hline()
                table.add_row(
                    ('Final GPU-Hours (climate-impact-tracker estimate)', str(extended_info["gpu_hours"])))
                table.add_hline()

    _generate_files(doc, os.path.join(_format_setname(setname) + '/', str(set_experiment_number)))

def main(arguments):

    parser=argparse.ArgumentParser(
        description = __doc__,
        formatter_class = argparse.RawDescriptionHelpFormatter)
    parser.add_argument('logdirs', nargs = '+',
                        help = "Input directories", type = str)
    parser.add_argument('--experiment_set_names', nargs="*")
    parser.add_argument('--experiment_set_filters', nargs="*")
    parser.add_argument('--ignore_hardware_comparison_warning', action="store_true")
    parser.add_argument('--executive_summary', action="store_true")
    parser.add_argument('--executive_summary_variables', nargs="*")
    args=parser.parse_args(arguments)
    
    # TODO: add flag for summary stats instead of table for each, this should create a shorter appendix

    aggregated_info = {}

    gpu_infos_all = {} 
    cpu_infos_all = {} 

    for exp_set, _filter in enumerate(args.experiment_set_filters):
        aggregated_info[args.experiment_set_names[exp_set]] = {}

        # Allow for a sort of regex filter
        if "*" in _filter:
            _filter = _filter.split("*")
        else:
            _filter = [_filter]
        def check(va):
            for _filt in _filter:
                if _filt not in va:
                    return False
            return True

        filtered_dirs = list(filter(check, args.logdirs))
        print("Filtered dirs: {}".format(",".join(filtered_dirs)))
        gpu_infos_all[args.experiment_set_names[exp_set]] = []
        cpu_infos_all[args.experiment_set_names[exp_set]] = []
        for i, x in enumerate(filtered_dirs):
            info = load_initial_info(x)
            gpu_infos_all[args.experiment_set_names[exp_set]].append(info["gpu_info"])
            cpu_infos_all[args.experiment_set_names[exp_set]].append(info["cpu_info"])
            extracted_info = gather_additional_info(info, x)
            _generate_experiment_table(x, info, extracted_info, args.experiment_set_names[exp_set], i)
            for key, value in extracted_info.items():
                if key not in aggregated_info[args.experiment_set_names[exp_set]]:
                    aggregated_info[args.experiment_set_names[exp_set]][key] = []
                aggregated_info[args.experiment_set_names[exp_set]][key].append(value)

        doc=Document()
        with doc.create(Section('Experiment Set {}'.format(args.experiment_set_names[exp_set]))):
            with doc.create(Subsection('Averaged')):
                with doc.create(Tabular('|r|c|')) as table:
                    table.add_hline()
                    for key, values in aggregated_info[args.experiment_set_names[exp_set]].items():
                        values_mean = np.mean(values)
                        values_stdder = scipy.stats.sem(values)
                        table.add_row((key, "{} +/- {} (stderr)".format(values_mean, values_stdder)))
                        table.add_hline()
            with doc.create(Subsection('Cumulative')):
                with doc.create(Tabular('|r|c|')) as table:
                    table.add_hline()
                    for key, values in aggregated_info[args.experiment_set_names[exp_set]].items():
                        values_summed = np.sum(values)
                        table.add_row((key, "{}".format(values_summed)))
                        table.add_hline()

        _generate_files(doc, os.path.join(_format_setname(args.experiment_set_names[exp_set]), 'summary'))

    if args.executive_summary:
        
        doc=Document()
        with doc.create(Section('Executive Summary')):
            formatting = '|' + '|'.join(['c']*(len(args.executive_summary_variables)+1)) + '|'
            with doc.create(Tabular(formatting)) as table:
                table.add_hline()
                table.add_row(["exp_name"] + args.executive_summary_variables)
                table.add_hline()
                for exp_name in args.experiment_set_names:
                    data = [exp_name]
                    for variable in args.executive_summary_variables:
                        values = aggregated_info[exp_name][variable]
                        values_mean = np.mean(values)
                        values_stdder = scipy.stats.sem(values)
                        data.append("{:.3f} +/- {:.2f}".format(values_mean, values_stdder))
                    table.add_row(data)
                table.add_hline()
                        
        _generate_files(doc, './exec_summary')


    pairwise_comparisons = combinations(args.experiment_set_names, 2)

    for pair1, pair2 in pairwise_comparisons:

        old_aggregate_info = aggregated_info[pair1]
        new_aggregate_info = aggregated_info[pair2]
        
        doc = Document()
            
        with doc.create(Section('Experiment Set Difference: {} v. {}'.format(pair1, pair2))):
            with doc.create(Subsection('Average Treatment Effect (Per Experiment in Experiment Set)')):
                with doc.create(Tabular('|r|c|')) as table:
                    table.add_hline()
                    for key, values in new_aggregate_info.items():
                        delta, delta_err = get_average_treatment_effect(old_aggregate_info[key], values)
                        _,p = run_test("Welch t-test", old_aggregate_info[key], values)
                        table.add_row((key, "{:.6g} +/- {:.6g} (stderr) (p={:.6g}, Welch's t-test)".format(delta, delta_err, p)))
                        table.add_hline()

            with doc.create(Subsection('Cumulative Difference (Per Experiment Set)')):
                with doc.create(Tabular('|r|c|')) as table:
                    table.add_hline()
                    for key, values in new_aggregate_info.items():
                        delta = np.sum(old_aggregate_info[key]) - np.sum(values) 
                        # delta_err = 1.96 * np.sqrt(np.var(values) / len(values) + \
                        #     np.var(old_aggregate_info[key]) / len(old_aggregate_info[key]))
        
                        table.add_row((key, "{}".format(delta)))
                        table.add_hline()
        _generate_files(doc, os.path.join('./summary_{}_v_{}'.format(_format_setname(pair1), _format_setname(pair2))))

        old_gpu_infos = gpu_infos_all[pair1]
        gpu_infos = gpu_infos_all[pair2]
        cpu_infos = cpu_infos_all[pair2]
        old_cpu_infos = cpu_infos_all[pair1]
        if args.ignore_hardware_comparison_warning:
            print("YOU ARE IGNORING HARDWARE COMPARISON WARNINGS, NOTE ANY ENERGY COMPARISON MAY NOT BE VALID BETWEEN TWO SETS OF EXPERIMENTS WITH DIFFERENT HARDWARE.")
        else:
            num_gpus = ([len(x) for x in gpu_infos])
            num_gpus_old = ([len(x) for x in old_gpu_infos])
            if sorted(num_gpus_old) != sorted(num_gpus):
                raise NotImplementedError("You're looking to compare two sets of experiments with a different heterogeneous make-up of GPU numbers.")

            ddiff = DeepDiff(gpu_infos, old_gpu_infos, ignore_order=True)
            if ddiff:
                pprint(ddiff)
                raise NotImplementedError("You're looking to compare two sets of heterogeneous GPUs for exp {}, {} that are of different compositions. This will result in uncomparable results.".format(pair1, pair2))

            # TODO: actual Hz is never the same so maybe look at some subset of metrics or make sure average Hz is somewhat similar
            ignore_cpu_attrs = ["hz_actual", "hz_actual_raw", "flags"]
            for cpu_info in cpu_infos:
                for attr in ignore_cpu_attrs:
                    if attr in cpu_info:
                        del cpu_info[attr]
            for cpu_info in old_cpu_infos:
                for attr in ignore_cpu_attrs:
                    if attr in cpu_info:
                        del cpu_info[attr]

            ddiff = DeepDiff(cpu_infos, old_cpu_infos, ignore_order=True)
            if ddiff:
                pprint(ddiff)
                raise NotImplementedError("You're looking to compare two sets of heterogeneous CPUs that are of different compositions. This will result in uncomparable results.")

    # doc.generate_tex(os.path.join('./', 'impact_appendix'))
    # doc.generate_pdf(os.path.join('./', 'impact_appendix'))

    # log average gpu/cpu usage
    # log cpu/gpu hours
    # can we also get energy in joules?

if __name__ == '__main__':
    sys.exit(main(sys.argv[1:]))
